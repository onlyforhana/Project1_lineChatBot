import requests
import json
from neo4j import GraphDatabase
from flask import Flask, request, jsonify
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import TextSendMessage
from sentence_transformers import SentenceTransformer
import pandas as pd
import faiss
import numpy as np
import os

# Neo4j configuration
URI = "neo4j://localhost:7687"
AUTH = ("neo4j", "theoneandonlyhana")

# Initialize Sentence Transformer model (cached to avoid reloading)
model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')

# Ollama API Configuration
OLLAMA_API_URL = "http://localhost:11434/api/generate"
OLLAMA_HEADERS = {
    "Content-Type": "application/json"
}

# Fetch greeting corpus and responses from Neo4j
def load_greetings():
    cypher_query = '''
    MATCH (n:Greeting) RETURN n.name as name, n.msg_reply as reply
    UNION 
    MATCH (q:FAQ) RETURN q.question as name, q.answer as reply;
    ''' 
    greeting_corpus = []
    greeting_responses = {}

    try:
        with GraphDatabase.driver(URI, auth=AUTH) as driver:
            with driver.session() as session:
                results = session.run(cypher_query)
                for record in results:
                    greeting_corpus.append(record['name'])
                    greeting_responses[record['name']] = record['reply']
    except Exception as e:
        print(f"Error fetching data from Neo4j: {e}")
        return [], {}
    
    return greeting_corpus, greeting_responses

# Load the corpus from Neo4j and create a FAISS index
def create_faiss_index(corpus):
    if not corpus:
        return None, None

    # Encode the text corpus
    vectors = model.encode(corpus)

    # Normalize vectors and create FAISS index
    vector_dimension = vectors.shape[1]
    faiss_index = faiss.IndexFlatL2(vector_dimension)
    faiss.normalize_L2(vectors)
    faiss_index.add(vectors)

    return faiss_index, vectors

# Search the FAISS index and return the closest result
def search_faiss(faiss_index, query, corpus, responses, threshold=0.5):
    query_vector = model.encode([query])
    faiss.normalize_L2(query_vector)
    distances, indices = faiss_index.search(query_vector, k=1)  # Find the closest match

    best_distance = distances[0][0]
    best_index = indices[0][0]

    if best_distance < threshold:
        matched_text = corpus[best_index]
        response = responses.get(matched_text, "Sorry, I don't understand.") + " (source: Neo4j)"
    else:
        response = "Sorry, I don't understand."

    return response

# Function to generate a response using Ollama API
def generate_response_with_ollama(prompt):
    payload = {
        "model": "supachai/llama-3-typhoon-v1.5",  # Adjust the model name if necessary
        "prompt": prompt,
        "stream": False
    }
    
    try:
        response = requests.post(OLLAMA_API_URL, headers=OLLAMA_HEADERS, data=json.dumps(payload))
        if response.status_code == 200:
            data = response.json()
            return data["response"] + " (source: generated by model)"
        else:
            print(f"Ollama API error: {response.status_code}, {response.text}")
            return "Sorry, I couldn't generate a response."
    except Exception as e:
        print(f"Error contacting Ollama API: {e}")
        return "Sorry, there was an error generating a response."

# Initialize data
greeting_corpus, greeting_responses = load_greetings()
faiss_index, encoded_vectors = create_faiss_index(greeting_corpus)

# Flask app
app = Flask(__name__)

@app.route("/", methods=['POST'])
def linebot():
    body = request.get_data(as_text=True)
    try:
        json_data = json.loads(body)
        access_token = os.getenv("LINE_ACCESS_TOKEN", "PpX5KafWR/PggcJnhY6h2hkf2BsHPNl2JbukLNUwytD6T9IOK5A5nUqqzqFT61g9hXaCYjla/Chs1LAaW0m3LkWa4KgHPwNko88FYT3i79UI7V78fuCM7dgt/61lcUnQFwyVsmwFabGsuiOVb1vzFgdB04t89/1O/w1cDnyilFU=")
        secret = os.getenv("LINE_SECRET", "1620670ad6a2d85f22cc94f4abf10398")
        line_bot_api = LineBotApi(access_token)
        handler = WebhookHandler(secret)
        signature = request.headers['X-Line-Signature']
        handler.handle(body, signature)
        
        msg = json_data['events'][0]['message']['text']
        reply_token = json_data['events'][0]['replyToken']
        
        # Perform the FAISS-based search
        response_msg = search_faiss(faiss_index, msg, greeting_corpus, greeting_responses)

        # If FAISS couldn't find a suitable match, use Ollama to generate a response
        if response_msg == "Sorry, I don't understand.":
            ollama_prompt = f"{msg} answer in 50 words and in Thai language"
            response_msg = generate_response_with_ollama(ollama_prompt)

        # Reply with the found/generated message
        line_bot_api.reply_message(reply_token, TextSendMessage(text=response_msg))
        print(f"Received message: {msg}, Reply token: {reply_token}")
    except InvalidSignatureError:
        return jsonify({"status": "invalid signature"}), 400
    except Exception as e:
        print(f"Error: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

    return 'OK'

if __name__ == '__main__':
    app.run(port=5000)
